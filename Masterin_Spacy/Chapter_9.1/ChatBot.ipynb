{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c80e6ab-3461-4bb1-aa43-c25df0d85834",
   "metadata": {},
   "source": [
    "<center><h1>ğ’«ğ“Šğ“‰ğ“‰ğ’¾ğ“ƒğ‘” ğ¸ğ“‹ğ‘’ğ“‡ğ“ğ“‰ğ’½ğ’¾ğ“ƒğ‘” ğ’¯ğ‘œğ‘”ğ‘’ğ“‰ğ’½ğ‘’ğ“‡:\n",
    "    ğ’Ÿğ‘’ğ“ˆğ’¾ğ‘”ğ“ƒğ’¾ğ“ƒğ‘” ğ’´ğ‘œğ“Šğ“‡ ğ’ğ’½ğ’¶ğ“‰ğ’·ğ‘œğ“‰ ğ“Œğ’¾ğ“‰ğ’½ ğ“ˆğ“…ğ’¶ğ’ğ“</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85abedb0-33b6-40a4-9251-7d0a9a563427",
   "metadata": {},
   "source": [
    "In this chapter, we are going to build a **NLU(Chatbot)** by whatever we learned still now, we use intent recoginiton and entity extraction. Then we will use all the techniques whatever we learned in this book. \n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/SpaCy_logo.svg/1200px-SpaCy_logo.svg.png\" width=\"600\"/></center>\n",
    "\n",
    "[**Codes**](https://github.com/PacktPublishing/Mastering-spaCy/tree/main/Chapter10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a728e-3e6e-4f64-870e-81bf040047ee",
   "metadata": {},
   "source": [
    "## Creating a ChatBot: \n",
    "\n",
    "Chatbot design datasets are usually in JSON format to maintain the dataset\n",
    "structure. Here, structure means the following:\n",
    "* Keeping the order of user and system utterances\n",
    "* Marking slots of the user utterances\n",
    "* Labeling the intent of the user utterances. \n",
    "\n",
    "We are going to use the **The Schema Guided Dialouge Dataset**. \n",
    "\n",
    "### Extracting City Names\n",
    "**Let's start by finding the City Entites in the user utterances, This is the restarant dataset. So, we need to get the city names first**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b816d1fc-7b79-4c76-af22-250bdf2fefee",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thinc.neural'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9076/2794980154.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'en_core_web_lg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utterances.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mutterances\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Downloads\\Anaconda_God\\envs\\aravind\\lib\\site-packages\\spacy\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# These are imported as part of the API\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mthinc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprefer_gpu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequire_gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'thinc.neural'"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "with open('utterances.txt', 'r') as utterances: \n",
    "    for utterance in utterrances: \n",
    "        utterance = utterance.strip() \n",
    "        \n",
    "        doc = nlp(utterance)\n",
    "        ents = doc.ents \n",
    "        \n",
    "        if ents: \n",
    "            for ent in ents: \n",
    "                if ent.label_ == \"GPE\": \n",
    "                    print(ent.text, \"\\t\", utterance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdf6b4d-b159-433f-9f15-6167975de659",
   "metadata": {},
   "source": [
    "### Extracting date and time entities\n",
    "\n",
    "[**You can refer everything here**](https://colab.research.google.com/drive/1mbdTTVbX9aPYkGTOw7sWis7G0iLuR1oG#scrollTo=ipQ9Y3m_sXAF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
